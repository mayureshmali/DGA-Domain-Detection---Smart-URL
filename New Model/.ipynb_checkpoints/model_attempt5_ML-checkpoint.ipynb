{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import tldextract\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000directory.com.ar</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000webhost.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>001fans.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01-telecharger.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>010shangpu.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain domain_type\n",
       "0  000directory.com.ar      benign\n",
       "1       000webhost.com      benign\n",
       "2          001fans.com      benign\n",
       "3   01-telecharger.com      benign\n",
       "4       010shangpu.com      benign"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set benign to 0 and dga to 1\n",
    "data['dt'] = pd.factorize(data['domain_type'])[0]\n",
    "#data.dtypes \n",
    "#(do i need to set dt to catagory? find out later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['extract'] = data['domain'].apply(lambda url: tldextract.extract(url).domain)\n",
    "X = data['extract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A Dicitonary of valid chars\n",
    "unique_chars = enumerate(set(''.join(X))) \n",
    "chars_dict = dict()\n",
    "for i, x in unique_chars: #index of enum starts with 0\n",
    "    #print('i: ' + str(i) + '  x: ' + x)\n",
    "    chars_dict[x] = i + 1 #leave 0 for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 1,\n",
       " '3': 2,\n",
       " '8': 3,\n",
       " 's': 4,\n",
       " 'x': 5,\n",
       " '5': 6,\n",
       " '9': 7,\n",
       " 'h': 8,\n",
       " 'e': 9,\n",
       " 'f': 10,\n",
       " 'j': 11,\n",
       " 'a': 12,\n",
       " '1': 13,\n",
       " '4': 14,\n",
       " 'y': 15,\n",
       " 'l': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'u': 19,\n",
       " '0': 20,\n",
       " 'k': 21,\n",
       " 'c': 22,\n",
       " '-': 23,\n",
       " 'n': 24,\n",
       " 'g': 25,\n",
       " '7': 26,\n",
       " 'd': 27,\n",
       " 'r': 28,\n",
       " 'w': 29,\n",
       " 'i': 30,\n",
       " 'v': 31,\n",
       " '2': 32,\n",
       " '6': 33,\n",
       " 't': 34,\n",
       " 'b': 35,\n",
       " 'm': 36,\n",
       " '\\n': 37,\n",
       " 'q': 38}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(list(enumerate(set(''.join(X))) ))\n",
    "chars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index 0 is also going to be a feature(padding/unknown).\n",
    "max_features_num = len(chars_dict) + 1\n",
    "\n",
    "#max length will be the max length of domain in our dataset\n",
    "maxlen = np.max([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert characters to int\n",
    "X_in_int = []\n",
    "for domain in X:\n",
    "    domain_in_int = []\n",
    "    for c in domain:\n",
    "        domain_in_int.append(chars_dict[c])\n",
    "    X_in_int.append(domain_in_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20, 20, 29, 9, 35, 8, 17, 4, 34]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_in_int[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144945, 56)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pad to max length using keras... do we need to use a certain max len?\n",
    "X = X_in_int\n",
    "X = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: dt, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.iloc[:, 2]\n",
    "Y.head()\n",
    "# len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model - XGBOOST\n",
    "# documentation https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11\n",
    "test_size = .33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "#len(X_train)+len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.08%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART two \n",
    "#https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 2} \n",
    "\n",
    "steps = 1000  # The number of training iterations\n",
    "\n",
    "\n",
    "#https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test accuracy on assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT THE TLDEXTRACT HERE as well\n",
    "\n",
    "test['extract'] = test['domain'].apply(lambda url: tldextract.extract(url).domain)\n",
    "XT = test['extract']\n",
    "\n",
    "XT_in_int = []\n",
    "for domain in XT:\n",
    "    domain_in_int_t = []\n",
    "    for c in domain:\n",
    "        domain_in_int_t.append(chars_dict[c])\n",
    "    XT_in_int.append(domain_in_int_t)\n",
    "\n",
    "#need to stick the url split library in here\n",
    "    # type(x1)\n",
    "# x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT_in_int[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = XT_in_int\n",
    "XT = sequence.pad_sequences(XT, maxlen=maxlen)\n",
    "XT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = xgb.DMatrix(XT)\n",
    "preds_test = model.predict(DT)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds_test = np.asarray([np.argmax(line) for line in preds_test])\n",
    "best_preds_test\n",
    "# test['threat']=best_preds_test\n",
    "\n",
    "# test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 0 to benign and 1 to dga\n",
    "con = []\n",
    "for i in best_preds_test:\n",
    "    if best_preds_test[i] == 0:\n",
    "        con.append('benign')\n",
    "    else:\n",
    "        con.append('dga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['threat']=con\n",
    "test\n",
    "\n",
    "test.to_csv('test_RESULTS.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
